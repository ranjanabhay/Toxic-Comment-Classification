{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Toxic Comment Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.head(n=5)\n",
      "test.head(n=5)\n",
      "                 id                                       comment_text  \\\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
      "\n",
      "                             lemmatized_comment_text  \n",
      "0  Explanation Why the edits made under my userna...  \n",
      "1  D'aww! He match this background colour I'm see...  \n",
      "2  Hey man, I'm really not trying to edit war. It...  \n",
      "3  \" More I can't make any real suggestion on imp...  \n",
      "4  You, sir, are my hero. Any chance you remember...  \n",
      "                                        comment_text                id  \\\n",
      "0  Explanation\\nWhy the edits made under my usern...  0000997932d777bf   \n",
      "1  D'aww! He matches this background colour I'm s...  000103f0d9cfb60f   \n",
      "2  Hey man, I'm really not trying to edit war. It...  000113f07ec002fd   \n",
      "3  \"\\nMore\\nI can't make any real suggestions on ...  0001b41b1c6bb37e   \n",
      "4  You, sir, are my hero. Any chance you remember...  0001d958c54c6e35   \n",
      "\n",
      "   identity_hate  insult                            lemmatized_comment_text  \\\n",
      "0            0.0     0.0  Explanation Why the edits made under my userna...   \n",
      "1            0.0     0.0  D'aww! He match this background colour I'm see...   \n",
      "2            0.0     0.0  Hey man, I'm really not trying to edit war. It...   \n",
      "3            0.0     0.0  \" More I can't make any real suggestion on imp...   \n",
      "4            0.0     0.0  You, sir, are my hero. Any chance you remember...   \n",
      "\n",
      "   obscene  severe_toxic  threat  toxic  \n",
      "0      0.0           0.0     0.0    0.0  \n",
      "1      0.0           0.0     0.0    0.0  \n",
      "2      0.0           0.0     0.0    0.0  \n",
      "3      0.0           0.0     0.0    0.0  \n",
      "4      0.0           0.0     0.0    0.0  \n",
      "preds [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "submissionid_dataframe                  id\n",
      "0  00001cee341fdb12\n",
      "1  0000247867823ef7\n",
      "2  00013b17ad220c46\n",
      "3  00017563c3f7919a\n",
      "4  00017695ad8997eb\n",
      "classification_dataframe       toxic  severe_toxic   obscene    threat    insult  identity_hate\n",
      "0  0.996459      0.156525  0.993518  0.025100  0.894226       0.227864\n",
      "1  0.009561      0.003322  0.005734  0.001860  0.008563       0.003440\n",
      "2  0.035904      0.004198  0.013681  0.001648  0.017273       0.004376\n",
      "3  0.005040      0.002359  0.003948  0.001169  0.004283       0.001127\n",
      "4  0.044560      0.003381  0.012329  0.001988  0.019022       0.003214\n",
      "submission_dataframe.head(n=5)\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.996459      0.156525  0.993518  0.025100  0.894226   \n",
      "1  0000247867823ef7  0.009561      0.003322  0.005734  0.001860  0.008563   \n",
      "2  00013b17ad220c46  0.035904      0.004198  0.013681  0.001648  0.017273   \n",
      "3  00017563c3f7919a  0.005040      0.002359  0.003948  0.001169  0.004283   \n",
      "4  00017695ad8997eb  0.044560      0.003381  0.012329  0.001988  0.019022   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.227864  \n",
      "1       0.003440  \n",
      "2       0.004376  \n",
      "3       0.001127  \n",
      "4       0.003214  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Read the train and test files\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "subm = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "#train = pd.read_csv('../input/train.csv')\n",
    "#test = pd.read_csv('../input/test.csv')\n",
    "#subm = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    return \" \".join([wnl.lemmatize(i) for i in text.split()])\n",
    "\n",
    "\n",
    "#train['new_comment_text'] = train['comment_text'].apply(lambda x : lemmatize_text(x))\n",
    "train['lemmatized_comment_text'] = train['comment_text'].apply(lemmatize_text)\n",
    "print(\"train.head(n=5)\")\n",
    "test['lemmatized_comment_text'] = train['comment_text'].apply(lemmatize_text)\n",
    "print(\"test.head(n=5)\")\n",
    "print(test.head(n=5))\n",
    "#print(train.head(n=5))\n",
    "nrow_train = train.shape[0]\n",
    "nrow_test = test.shape[0]\n",
    "\n",
    "\n",
    "# Concat the train and test dataset\n",
    "df = pd.concat([train,test],axis=0)\n",
    "df.fillna(\"missing\")\n",
    "print(df.head(n=5))\n",
    "\n",
    "# Instantiate TfidfVectorizer\n",
    "\n",
    "tfIdfVectorizer = TfidfVectorizer(stop_words='english',max_features=25000,ngram_range=(1,2))\n",
    "#X = tfIdfVectorizer.fit_transform(df['comment_text'])\n",
    "X = tfIdfVectorizer.fit_transform(df['comment_text'])\n",
    "columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "preds = np.zeros((test.shape[0],len(columns)))\n",
    "print('preds',preds)\n",
    "# print(preds.shape)\n",
    "loss = []\n",
    "\n",
    "for i,j in enumerate(columns):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X[:nrow_train],train[j])\n",
    "    preds[:,i] = model.predict_proba(X[nrow_train:])[:,1]\n",
    "    pred_train = model.predict_proba(X[:nrow_train])[:,1]\n",
    "    #print(\"type pred_train\",type(preds))\n",
    "    #print('ROC AUC',roc_auc_score(train[j],pred_train))\n",
    "    loss.append(roc_auc_score(train[j],pred_train))\n",
    "    \n",
    "#print(\"loss\",loss)\n",
    "#print(\"preds.shape\",preds.shape)\n",
    "#print(\"preds.shape[0]\",preds.shape[0])\n",
    "#print(\"pred\",pred)\n",
    "\n",
    "submissionid_dataframe = pd.DataFrame({'id':subm['id']})\n",
    "print('submissionid_dataframe',submissionid_dataframe.head(n=5))\n",
    "classification_dataframe = pd.DataFrame(preds,columns=columns)\n",
    "print('classification_dataframe',classification_dataframe.head(n=5))\n",
    "\n",
    "submission_dataframe = pd.concat([submissionid_dataframe,classification_dataframe],axis=1)\n",
    "print(\"submission_dataframe.head(n=5)\")\n",
    "print(submission_dataframe.head(n=5))\n",
    "submission_dataframe.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Fit toxic\n",
      "ROC AUC: 0.984002188012\n",
      "===Fit severe_toxic\n",
      "ROC AUC: 0.992286301018\n",
      "===Fit obscene\n",
      "ROC AUC: 0.993013888262\n",
      "===Fit threat\n",
      "ROC AUC: 0.995287025481\n",
      "===Fit insult\n",
      "ROC AUC: 0.987352370521\n",
      "===Fit identity_hate\n",
      "ROC AUC: 0.990020431257\n",
      "mean column-wise ROC AUC: 0.990327034092\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "subm = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat([train['comment_text'], test['comment_text']], axis=0)\n",
    "df = df.fillna(\"unknown\")\n",
    "nrow_train = train.shape[0]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=50000)\n",
    "X = vectorizer.fit_transform(df)\n",
    "\n",
    "col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "preds = np.zeros((test.shape[0], len(col)))\n",
    "\n",
    "\n",
    "\n",
    "loss = []\n",
    "\n",
    "for i, j in enumerate(col):\n",
    "    print('===Fit '+j)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X[:nrow_train], train[j])\n",
    "    preds[:,i] = model.predict_proba(X[nrow_train:])[:,1]\n",
    "    \n",
    "    pred_train = model.predict_proba(X[:nrow_train])[:,1]\n",
    "    print('ROC AUC:', roc_auc_score(train[j], pred_train))\n",
    "    loss.append(roc_auc_score(train[j], pred_train))\n",
    "    \n",
    "print('mean column-wise ROC AUC:', np.mean(loss))\n",
    "    \n",
    "    \n",
    "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(preds, columns = col)], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Dogs\n",
      "8 Cats\n",
      "9 Turtles\n",
      "10 Rabbits\n"
     ]
    }
   ],
   "source": [
    "pets = ('Dogs','Cats','Turtles','Rabbits')\n",
    "for i,pet in enumerate(pets,7):\n",
    "    print(i,pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 toxic\n",
      "1 severe_toxic\n",
      "2 obscene\n",
      "3 threat\n",
      "4 insult\n",
      "5 identity_hate\n"
     ]
    }
   ],
   "source": [
    "columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "for i,j in enumerate(columns):\n",
    "    print(i,j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Classifiers\n",
      "ABCDEF GHIJKLMNOPQRSTUVWXYZ\n",
      "This is not the place I want to be but at this point I do not have any choice\n",
      "I am trying and I need to get this done as soon as possible\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict Classifiers\")\n",
    "print(\"ABCDEF GHIJKLMNOPQRSTUVWXYZ\")\n",
    "print(\"This is not the place I want to be but at this point I do not have any choice\")\n",
    "print(\"I am trying and I need to get this done as soon as possible\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
